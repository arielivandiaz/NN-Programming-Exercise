Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_squared_error 	
43.9322350025	0.737866163254	7.52%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_absolute_error 	
43.9338259697	0.751413822174	17.14%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.7244529724	0.733373165131	8.23%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.9213089943	0.695724010468	7.72%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : squared_hinge 	
43.3219771385	0.720273017883	7.88%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : hinge 	
43.8744688034	0.712017059326	9.94%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : categorical_hinge 	
44.2564108372	0.734172105789	8.21%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : logcosh 	
43.9472579956	0.73774600029	7.76%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : categorical_crossentropy 	
44.558724165	0.716862201691	7.22%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : sparse_categorical_crossentropy 	
####
Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_squared_error 	
47.2753942013	0.813138008118	7.64%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_absolute_error 	
47.1424429417	0.793112039566	7.81%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_absolute_percentage_error 	
46.60039711	0.78250002861	7.62%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
47.1246290207	0.797490119934	7.56%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : squared_hinge 	
46.9828460217	0.799492120743	7.44%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : hinge 	
46.8887381554	0.795562982559	8.17%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : categorical_hinge 	
47.2778890133	0.794810771942	7.55%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : logcosh 	
46.7367408276	0.816440105438	7.63%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : categorical_crossentropy 	
47.1836259365	0.811665058136	7.34%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : sparse_categorical_crossentropy 	
####
Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_error 	
43.7531559467	0.744359016418	7.86%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_error 	
43.5310869217	0.761348962784	8.04%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.2650899887	0.732834815979	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.5908398628	0.735497951508	7.85%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : squared_hinge 	
43.3701219559	0.757890939713	7.72%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : hinge 	
43.637665987	0.729873180389	8.44%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_hinge 	
43.9125490189	0.732260942459	7.74%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : logcosh 	
43.4928929806	0.744653940201	7.79%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_crossentropy 	
43.7726449966	0.733960151672	7.65%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : sparse_categorical_crossentropy 	
Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : sparse_categorical_crossentropy 	
Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : sparse_categorical_crossentropy 	
Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_error 	
43.6046500206	0.748682975769	7.86%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_error 	
43.6470899582	0.744212150574	8.04%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.248745203	0.732674837112	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.5655710697	0.719657897949	7.85%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : squared_hinge 	
43.2036838531	0.735579013824	7.72%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : hinge 	
43.6224029064	0.742391109467	8.45%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_hinge 	
43.8919348717	0.725205898285	7.76%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : logcosh 	
43.6932270527	0.727223157883	7.79%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_crossentropy 	
44.0126168728	0.741374969482	7.65%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : binary_crossentropy 	
44.050714016	0.749803066254	1.46%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : kullback_leibler_divergence 	
43.4652841091	0.739233970642	7.84%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : poisson 	
43.128562212	0.738197088242	8.02%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_error 	
43.8407568932	0.75332403183	7.86%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_error 	
43.6951329708	0.74104309082	8.04%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.1019921303	0.718045949936	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.4887049198	0.708961963654	7.85%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : squared_hinge 	
43.3531019688	0.730358839035	7.72%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : hinge 	
43.4496469498	0.722177028656	8.44%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_hinge 	
43.8357892036	0.722563028336	7.73%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : logcosh 	
43.8333060741	0.732110023499	7.79%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_crossentropy 	
44.2283630371	0.741358995438	7.65%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : binary_crossentropy 	
44.4983959198	0.745187997818	1.46%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : kullback_leibler_divergence 	
43.7331080437	0.712223052979	7.84%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : poisson 	
43.6392300129	0.762403011322	8.02%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_error 	
43.6740939617	0.735306978226	7.86%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_error 	
43.5444941521	0.734071016312	8.04%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.2743501663	0.719027996063	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.6851570606	0.722733974457	7.85%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : squared_hinge 	
43.3748581409	0.739817142487	7.72%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : hinge 	
43.6967720985	0.738637924194	8.44%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_hinge 	
43.7268061638	0.729630947113	7.75%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : logcosh 	
43.7020750046	0.746145963669	7.79%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : categorical_crossentropy 	
44.0982100964	0.747867107391	7.66%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : binary_crossentropy 	
44.1678190231	0.746437072754	1.46%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : kullback_leibler_divergence 	
43.9042379856	0.732162952423	7.84%	Test: simple_NN 	Optimization: nadam 	L1 : tanh 	L2 : softmax 	loss : poisson 	
43.6644899845	0.745369911194	8.02%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_squared_error 	
43.9488830566	0.74749994278	7.63%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_absolute_error 	
44.0446009636	0.733363866806	8.97%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.4587168694	0.712436914444	8.60%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.6890370846	0.72459602356	7.76%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : squared_hinge 	
43.5757470131	0.738744020462	7.81%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : hinge 	
43.570330143	0.72052693367	10.04%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : categorical_hinge 	
43.9465517998	0.721104860306	8.20%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : logcosh 	
43.6580810547	0.72830080986	7.78%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : categorical_crossentropy 	
43.9864499569	0.730495929718	7.36%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : binary_crossentropy 	
43.7247030735	0.728042125702	1.39%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : kullback_leibler_divergence 	
43.6213068962	0.718632936478	7.41%	Test: simple_NN 	Optimization: nadam 	L1 : relu 	L2 : softmax 	loss : poisson 	
43.5628461838	0.725919008255	7.49%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_squared_error 	
46.9974169731	0.807687997818	7.48%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_absolute_error 	
46.7705869675	0.800585031509	7.83%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_absolute_percentage_error 	
46.5508449078	0.810769796371	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
46.8303089142	0.804349899292	7.27%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : squared_hinge 	
47.0078620911	0.805858135223	7.75%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : hinge 	
46.9709308147	0.818880081177	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : categorical_hinge 	
46.8882160187	0.79306101799	7.56%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : logcosh 	
46.9639468193	0.810207843781	7.39%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : categorical_crossentropy 	
47.1834340096	0.797603845596	7.42%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : binary_crossentropy 	
47.0222990513	0.823632001877	1.43%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : kullback_leibler_divergence 	
46.5542340279	0.810431003571	7.35%	Test: simple_NN 	Optimization: nadam 	L1 : selu 	L2 : softmax 	loss : poisson 	
46.3566548824	0.80283498764	7.50%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : mean_squared_error 	
42.56270504	0.717061042786	7.36%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : mean_absolute_error 	
42.6960411072	0.725244045258	8.04%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : mean_absolute_percentage_error 	
42.5712327957	0.713629961014	7.92%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
42.5918030739	0.704426050186	7.50%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : squared_hinge 	
42.9531009197	0.721030950546	7.76%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : hinge 	
42.7963628769	0.714784860611	8.26%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : categorical_hinge 	
43.2440719604	0.704891204834	7.89%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : logcosh 	
42.6911869049	0.72328710556	7.92%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : categorical_crossentropy 	
42.8379819393	0.720935821533	8.17%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : binary_crossentropy 	
42.9310700893	0.727301836014	1.46%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : kullback_leibler_divergence 	
43.18582201	0.706027030945	7.86%	Test: simple_NN 	Optimization: nadam 	L1 : linear 	L2 : softmax 	loss : poisson 	
42.8551259041	0.731416940689	7.97%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : mean_squared_error 	
43.2840089798	0.738184928894	7.49%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : mean_absolute_error 	
43.4189510345	0.739336013794	8.13%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : mean_absolute_percentage_error 	
43.224864006	0.715546131134	7.81%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : mean_squared_logarithmic_error 	
43.4786810875	0.711165904999	7.46%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : squared_hinge 	
43.3445820808	0.706602096558	7.74%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : hinge 	
43.2173659801	0.71054816246	7.94%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : categorical_hinge 	
43.9979438782	0.728951931	7.95%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : logcosh 	
43.6428768635	0.712343931198	7.69%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : categorical_crossentropy 	
43.7942609787	0.729362010956	7.90%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : binary_crossentropy 	
44.4103329182	0.728665113449	1.50%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : kullback_leibler_divergence 	
43.6471850872	0.704650163651	7.78%	Test: simple_NN 	Optimization: nadam 	L1 : elu 	L2 : softmax 	loss : poisson 	
43.5874929428	0.727558135986	7.87%	